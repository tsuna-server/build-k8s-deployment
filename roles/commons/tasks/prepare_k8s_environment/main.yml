---
- name: "Create a \"/etc/modules-load.d/k8s.conf\" for bridges of IPv4"
  ansible.builtin.copy:
    dest: /etc/modules-load.d/k8s.conf
    content: |
      overlay
      br_netfilter
  notify: Run sysctl system

- name: "Create a \"/etc/sysctl.d/k8s.conf\" for bridges of IPv4"
  ansible.builtin.copy:
    dest: /etc/sysctl.d/k8s.conf
    content: |
      net.bridge.bridge-nf-call-iptables  = 1
      net.bridge.bridge-nf-call-ip6tables = 1
      net.ipv4.ip_forward                 = 1
  notify: Run sysctl system

- name: "Run notified handler of sysctl(Run sysctl system)"
  meta: flush_handlers


- name: "Add gpg key for kubernetes from \"https://packages.cloud.google.com/apt/doc/apt-key.gpg\" to \"/etc/apt/keyrings/kubernetes-archive-keyring.gpg\""
  ansible.builtin.apt_key:
    id: B53DC80D13EDEF05
    url: https://packages.cloud.google.com/apt/doc/apt-key.gpg
    keyring: /etc/apt/keyrings/kubernetes-archive-keyring.gpg
    state: present

# When the distribution is jammy, use repository for xenial so far because there are no repository for jammy in https://apt.kubernetes.io/.
- name: "Declare k8s_distribution_name for specifying apt_repository"
  set_fact:
    k8s_distribution_name: "{% if ansible_distribution_release == 'jammy' %}xenial{% else %}{{ ansible_distribution_release }}{% endif %}"

- name: "Repository \"https://apt.kubernetes.io/ kubernetes-{{ k8s_distribution_name }} main\""
  ansible.builtin.apt_repository:
    repo: "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-{{ k8s_distribution_name }} main"
    state: present

- name: "Install kubernetes packages"
  apt:
    name: ["kubelet", "kubeadm", "kubectl"]
    state: present
    update_cache: yes

- name: Install docker and its dependecies
  apt: 
    name: ["docker.io"]
    state: present
    update_cache: yes

- name: "Create a directory /etc/containerd/"
  ansible.builtin.file:
    path: /etc/containerd
    state: directory
    mode: '0755'

- name: "Get output of a command \"containerd config default\""
  shell: "containerd config default"
  register: output_of_a_command

- name: "Create a file \"/etc/containerd/config.toml\" by running a command \"containerd config default > /etc/containerd/config.toml\""
  copy:
    dest: /etc/containerd/config.toml
    content: "{{ output_of_a_command.stdout }}\n"
  notify: ["Restart containerd", "Restart kubelet"]

- name: "Replace a line \"SystemdCgroup\" in /etc/containerd/config.toml"
  ansible.builtin.lineinfile:
    path: /etc/containerd/config.toml
    regexp: '.* SystemdCgroup += +false.*'
    line: "SystemdCgroup = true"
  notify: ["Restart containerd", "Restart kubelet"]

- name: "Enable kubelet"
  ansible.builtin.service:
    name: kubelet
    enabled: yes

# Flush handlers
- name: "Run notified handler of sysctl(\"Restart containerd\", \"Restart kubelet\")"
  meta: flush_handlers

- name: "Block of instructions for k8s master nodes"
  block:
    - name: "\"kubeadm config images pull\" on master node"
      shell: "kubeadm config images pull"

    - name: "Check whether k8s cluster has already initialized"
      ansible.builtin.script: ./check_whether_k8s_cluster_has_already_initialized.sh
      register: result_of_command
      failed_when: (result_of_command.rc not in [0, 1])

    - name: "Init k8s cluster"
      command:
        argv: ["kubeadm", "init", "--apiserver-advertise-address=192.168.255.11", "--apiserver-cert-extra-sans=192.168.255.11", "--node-name", "k8s-master", "--pod-network-cidr=192.168.255.0/24"]
      register: result
      when: result_of_command.rc == 0

    - name: "Create a directory \"{{ ansible_env.HOME }}/.kube\" if it does not exist"
      ansible.builtin.file:
        path: "{{ ansible_env.HOME }}/.kube"
        state: directory
        mode: '0640'

    - name: "Copy kube config to {{ ansible_env.HOME }}/.kube/config"
      ansible.builtin.copy:
        remote_src: true
        src: "/etc/kubernetes/admin.conf"
        dest: "{{ ansible_env.HOME }}/.kube/config"
        owner: root
        group: root
        mode: '0640'

    - name: "Download a manifest of Calio from \"https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml\""
      get_url:
        url: https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml
        dest: "{{ ansible_env.HOME }}/tigera-operator.yaml"

    # TODO: This instruction should be checked whether tigera-operator.yaml has already applied.
    - name: "kubectl create -f tigera-operator.yaml"
      shell: "kubectl create -f {{ ansible_env.HOME }}/tigera-operator.yaml"
      register: kubectl_result
      retries: 360
      delay: 5
      timeout: 60
      until: kubectl_result is success
      args:
        creates: "{{ ansible_env.HOME }}/.kubectl_create_tigera_operator_yaml_has_already_created"

    - name: "Create \"/root/.kubectl_create_tigera_operator_yaml_has_already_created\" if \"kubectl create -f tigera-operator.yaml\" was succeeded."
      ansible.builtin.file:
        path: "{{ ansible_env.HOME }}/.kubectl_create_tigera_operator_yaml_has_already_created"
        state: touch
        mode: '0640'

    - name: "Download a manifest of Calio from \"https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/custom-resources.yaml\""
      get_url:
        url: https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/custom-resources.yaml
        dest: "{{ ansible_env.HOME }}/custom-resources.yaml"

    - name: "Replace cidr \"192.168.0.0\" to \"10.10.0.0\""
      ansible.builtin.replace:
        path: "{{ ansible_env.HOME }}/custom-resources.yaml"
        regexp: '^(\s+)cidr: 192\.168\.0\.0/16(.*)$'
        replace: '\1cidr: 10.10.0.0/16\2'

    - name: "Create Calico network with command \"kubectl create -f custom-resources.yaml\""
      shell: "kubectl create -f {{ ansible_env.HOME }}/custom-resources.yaml"
      register: kubectl_result
      retries: 360
      delay: 5
      timeout: 10
      until: kubectl_result is success
      args:
        creates: "{{ ansible_env.HOME }}/.kubectl_create_custom_resources_yaml_has_already_created"

    - name: "Create \"{{ ansible_env.HOME }}/.kubectl_create_custom_resources_yaml_has_already_created\" if \"kubectl create -f custom-resources.yaml\" was succeeded."
      ansible.builtin.file:
        path: "{{ ansible_env.HOME }}/.kubectl_create_custom_resources_yaml_has_already_created"
        state: touch
        mode: '0640'

    # Preparing weave net to be ready to each k8s nodes.

    - name: "Download a manifest of Weave daemon set."
      get_url:
        url: https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml
        dest: "{{ ansible_env.HOME }}/weave-daemonset-k8s.yaml"

    - name: "Apply Weave daemonset with a command \"kubectl apply -f {{ ansible_env.HOME }}/weave-daemonset-k8s.yaml\""
      shell: "kubectl apply -f {{ ansible_env.HOME }}/weave-daemonset-k8s.yaml"
      register: kubectl_result
      retries: 360
      delay: 5
      timeout: 10
      until: kubectl_result is success

    # # To get token for joining k8s cluster
    # kubeadm token list -o json | jq -r '.token'
    # # Getting discovery-token-ca-cert-hash
    # openssl x509 -in /etc/kubernetes/pki/ca.crt -noout -pubkey | openssl rsa -pubin -outform DER 2>/dev/null | sha256sum | cut -d' ' -f1

    - name: "Get a token for joining k8s cluster"
      ansible.builtin.script: ./get_token_for_joining_k8s_cluster.sh
      register: result

    - name: "Save a token for joining k8s cluster to localhost(Ansible orchestrator)"
      local_action:
        module: copy
        content: "{{ result.stdout }}"
        dest: .k8s_joining_token.txt

    - name: "Get a discovery-token-ca-cert-hash for joining k8s cluster"
      ansible.builtin.script: ./get_discovery_token_ca_cert_hash.sh
      register: result

    - name: "Save a discovery-token-ca-cert-hash for joining k8s cluster to localhost(Ansible orchestrator)"
      local_action:
        module: copy
        content: "{{ result.stdout }}"
        #dest: .buffer/k8s_discovery_token_ca_cert_hash.txt
        dest: .k8s_discovery_token_ca_cert_hash.txt

  when: "'k8s-master' in group_names"

- name: "Block of instructions for k8s member nodes"
  block:
    - name: "Look up k8s_joining_token"
      set_fact:
        k8s_joining_token: "{{ lookup('ansible.builtin.file', './.k8s_joining_token.txt') }}"

    - name: "Failed if a variable k8s_joining_token has empty"
      ansible.builtin.fail:
        msg: "ERROR: A variable \"k8s_joining_token\" has empty. It might also mean that getting k8s_joining_token from k8s master node has failed."
      when: k8s_joining_token == ""

    - name: "Look up k8s_discovery_token_ca_cert_hash.txt"
      set_fact:
        k8s_discovery_token_ca_cert_hash: "{{ lookup('ansible.builtin.file', './.k8s_discovery_token_ca_cert_hash.txt') }}"

    - name: "Failed if a variable k8s_discovery_token_ca_cert_hash has empty"
      ansible.builtin.fail:
        msg: "ERROR: A variable \"k8s_discovery_token_ca_cert_hash\" has empty. It might also mean that getting k8s_discovery_token_ca_cert_hash from k8s master node has failed."
      when: k8s_discovery_token_ca_cert_hash == ""

    #- name: "Debug variables \"k8s_joining_token\" and \"k8s_discovery_token_ca_cert_hash\""
    #  ansible.builtin.debug:
    #    msg: "k8s_joining_token={{ k8s_joining_token }}, k8s_discovery_token_ca_cert_hash={{ k8s_discovery_token_ca_cert_hash }}"

    - name: "Run a command \"kubeadm join <master_node_ip:port> --token <token> --discovery-token-ca-cert-hash <hash>\""
      ansible.builtin.command:
        argv: ["kubeadm", "join", "192.168.255.11:6443", "--token", "{{ k8s_joining_token }}", "--discovery-token-ca-cert-hash", "sha256:{{ k8s_discovery_token_ca_cert_hash }}"]
      args:
        creates: "/root/.kubeadm_join_has_already_done"

    - name: "Create \"/root/.kubeadm_join_has_already_done\" if \"kubeadm join <master_node_ip:port> --token <token> --discovery-token-ca-cert-hash <hash>\" was succeeded"
      ansible.builtin.file:
        path: "/root/.kubeadm_join_has_already_done"
        state: touch
        mode: '0640'

  when: "'k8s' in group_names"

