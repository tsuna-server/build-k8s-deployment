---
- name: "Create a \"/etc/modules-load.d/k8s.conf\" for bridges of IPv4"
  ansible.builtin.copy:
    dest: /etc/modules-load.d/k8s.conf
    content: |
      overlay
      br_netfilter
  notify: Run sysctl system

- name: "Create a \"/etc/sysctl.d/k8s.conf\" for bridges of IPv4"
  ansible.builtin.copy:
    dest: /etc/sysctl.d/k8s.conf
    content: |
      net.bridge.bridge-nf-call-iptables  = 1
      net.bridge.bridge-nf-call-ip6tables = 1
      net.ipv4.ip_forward                 = 1
  notify: Run sysctl system

- name: "Run notified handler of sysctl(Run sysctl system)"
  meta: flush_handlers


- name: "Add gpg key for kubernetes from \"https://packages.cloud.google.com/apt/doc/apt-key.gpg\" to \"/etc/apt/keyrings/kubernetes-archive-keyring.gpg\""
  ansible.builtin.apt_key:
    id: B53DC80D13EDEF05
    url: https://packages.cloud.google.com/apt/doc/apt-key.gpg
    keyring: /etc/apt/keyrings/kubernetes-archive-keyring.gpg
    state: present

# When the distribution is jammy, use repository for xenial so far because there are no repository for jammy in https://apt.kubernetes.io/.
- name: "Declare k8s_distribution_name for specifying apt_repository"
  set_fact:
    k8s_distribution_name: "{% if ansible_distribution_release == 'jammy' %}xenial{% else %}{{ ansible_distribution_release }}{% endif %}"

- name: "Repository \"https://apt.kubernetes.io/ kubernetes-{{ k8s_distribution_name }} main\""
  ansible.builtin.apt_repository:
    repo: "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-{{ k8s_distribution_name }} main"
    state: present

- name: "Install kubernetes packages"
  apt:
    name: ["kubelet", "kubeadm", "kubectl"]
    state: present
    update_cache: yes

- name: Install docker and its dependecies
  apt: 
    name: ["docker.io"]
    state: present
    update_cache: yes

- name: "Create a directory /etc/containerd/"
  ansible.builtin.file:
    path: /etc/containerd
    state: directory
    mode: '0755'

#- name: "Create a file \"/etc/containerd/config.toml\""
#  copy:
#    dest: /etc/containerd/config.toml
#    content: "containerd config default"
#    mode: '0644'
#  notify: ["Restart containerd", "Restart kubelet"]

- name: "Get output of a command \"containerd config default\""
  shell: "containerd config default"
  register: output_of_a_command

- name: "Create a file \"/etc/containerd/config.toml\" by running a command \"containerd config default > /etc/containerd/config.toml\""
  copy:
    dest: /etc/containerd/config.toml
    content: "{{ output_of_a_command.stdout }}\n"
  notify: ["Restart containerd", "Restart kubelet"]

- name: "Replace a line \"SystemdCgroup\" in /etc/containerd/config.toml"
  ansible.builtin.lineinfile:
    path: /etc/containerd/config.toml
    regexp: '.* SystemdCgroup += +false.*'
    line: "SystemdCgroup = true"
  notify: ["Restart containerd", "Restart kubelet"]

- name: "Enable kubelet"
  ansible.builtin.service:
    name: kubelet
    enabled: yes

# Flush handlers
- name: "Run notified handler of sysctl(\"Restart containerd\", \"Restart kubelet\")"
  meta: flush_handlers

- name: "Block of instructions for k8s master nodes"
  block:
    - name: "\"kubeadm config images pull\" on master node"
      shell: "kubeadm config images pull"

    - name: "Check whether k8s cluster has already initialized"
      ansible.builtin.script: ./check_whether_k8s_cluster_has_already_initialized.sh
      register: result_of_command

    - name: "Init k8s cluster"
      command:
        argv: ["kubeadm", "init", "--apiserver-advertise-address=192.168.255.11", "--apiserver-cert-extra-sans=192.168.255.11", "--node-name", "k8s-master", "--pod-network-cidr=192.168.255.0/24"]
      register: result
      when: result_of_command.rc == 0
      failed_when: (result_of_command.rc not in [0, 1])

    - name: "Create a directory \"{{ ansible_env.HOME }}/.kube\" if it does not exist"
      ansible.builtin.file:
        path: "{{ ansible_env.HOME }}/.kube"
        state: directory
        mode: '0640'

    - name: "Copy kube config to {{ ansible_env.HOME }}/.kube/config"
      ansible.builtin.copy:
        remote_src: true
        src: "/etc/kubernetes/admin.conf"
        dest: "{{ ansible_env.HOME }}/.kube/config"
        owner: root
        group: root
        mode: '0640'

    - name: "Download a manifest of Calio from \"https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml\""
      get_url:
        url: https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml
        dest: "{{ ansible_env.HOME }}/tigera-operator.yaml"

    - name: "kubectl create -f tigera-operator.yaml"
      shell: "kubectl create -f {{ ansible_env.HOME }}/tigera-operator.yaml"
      register: kubectl_result
      retries: 360
      delay: 5
      timeout: 60
      until: kubectl_result is success

    - name: "Download a manifest of Calio from \"https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/custom-resources.yaml\""
      get_url:
        url: https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/custom-resources.yaml
        dest: "{{ ansible_env.HOME }}/custom-resources.yaml"

    - name: "Replace cidr \"192.168.0.0\" to \"10.10.0.0\""
      lineinfile:
        path: "custom-resources.yaml"
        regexp: 'cidr: 192\.168\.0\.0/16'
        line: 'cidr: 10.10.0.0/16'

    - name: "kubectl create -f custom-resources.yaml"
      shell: "kubectl create -f {{ ansible_env.HOME }}/custom-resources.yaml"
      register: kubectl_result
      retries: 360
      delay: 5
      timeout: 10
      until: kubectl_result is success

  when: "'k8s-master' in group_names"

#- name: "Block of instructions for k8s nodes"
#    #- name: "Join a k8s cluster"
#    #  # TODO: 
#    #  # kubeadm join 172.31.1.11:6443 --token <token> --discovery-token-ca-cert-hash <hash>
#
#  when: "'k8s' in group_names"

